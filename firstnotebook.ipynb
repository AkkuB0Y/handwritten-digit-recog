{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Akshay's First Jupyter Notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "\n",
    "    'train': DataLoader(train_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1),\n",
    "    \n",
    "    'test': DataLoader(test_data,\n",
    "                       batch_size=100,\n",
    "                       shuffle=True,\n",
    "                       num_workers=1)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x11a73e690>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x106bf5bb0>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # kernel moves across and ret scores!\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # bigger kernel\n",
    "        self.conv2_drop = nn.Dropout2d() # dropout layer\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        # print(f\"After conv1 and max_pool2d: {x.shape}\")\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # print(f\"After conv2, conv2_drop, and max_pool2d: {x.shape}\")\n",
    "        \n",
    "        x = x.view(-1, 320)  # Flatten\n",
    "        # print(f\"After flattening: {x.shape}\")\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(f\"After fc1: {x.shape}\")\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        # print(f\"After fc2: {x.shape}\")\n",
    "        \n",
    "        return F.softmax(x, dim=1)  # Include dim=1 for softmax along the correct dimension\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # in case u have GPU\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch): # training process!\n",
    "    model.train() # put in training mode!\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        # calculate loss:\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Review This!\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} ({100. *batch_idx / len(loaders['train']):.0f}%)]\\t{loss.item():.6f})\")\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0 \n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target  in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True) # prediction!\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders['test'].dataset)} ({100. * correct / len(loaders['test'].dataset):.0f}%\\n)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.302879)\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t2.283473)\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t2.133849)\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t2.058207)\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.912489)\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.820083)\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.760203)\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t1.720025)\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t1.726641)\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.750404)\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.662349)\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t1.739111)\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.706905)\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.693145)\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.621755)\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.653069)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.743558)\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.670620)\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.630833)\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.639689)\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.662201)\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.652826)\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.574318)\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.619946)\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.631192)\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.589771)\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.623018)\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.557302)\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.618808)\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.576903)\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy 9414/10000 (94%\n",
      ")\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.604372)\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.618900)\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.590670)\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.638356)\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.590419)\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.600167)\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.577599)\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.625411)\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.532969)\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.589209)\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.538366)\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.616832)\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.548302)\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.545107)\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.608290)\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.624622)\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.545206)\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.558606)\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.548502)\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.526683)\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.574401)\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.581871)\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.570927)\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.608553)\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.575434)\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.565457)\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.628349)\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.574492)\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.547844)\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.563523)\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy 9550/10000 (96%\n",
      ")\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.594918)\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t1.592446)\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t1.577190)\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t1.547277)\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t1.554568)\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t1.616728)\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t1.580243)\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t1.539328)\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t1.552166)\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t1.587899)\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t1.537643)\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t1.570750)\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t1.585445)\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t1.539287)\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t1.509160)\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.556822)\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t1.560499)\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t1.557111)\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t1.572220)\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t1.540168)\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t1.566461)\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t1.562168)\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t1.536234)\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t1.553072)\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t1.540387)\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t1.579168)\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t1.531371)\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t1.565621)\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t1.530703)\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t1.550720)\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9601/10000 (96%\n",
      ")\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.597918)\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t1.505379)\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t1.583644)\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t1.539662)\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t1.552964)\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t1.563755)\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t1.500230)\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t1.541000)\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t1.577573)\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t1.589542)\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t1.547392)\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t1.541918)\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t1.552050)\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t1.537873)\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t1.586663)\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.532667)\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t1.565787)\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t1.549376)\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t1.567356)\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t1.573963)\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t1.521380)\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t1.525369)\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t1.545683)\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t1.513805)\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t1.539090)\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t1.601680)\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t1.520339)\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t1.573949)\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t1.554072)\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t1.510466)\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9656/10000 (97%\n",
      ")\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.543998)\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t1.554587)\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t1.536938)\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t1.503400)\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t1.509335)\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t1.558336)\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t1.564212)\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t1.543075)\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t1.559039)\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t1.583621)\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t1.495384)\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t1.556410)\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t1.551680)\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t1.554129)\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t1.511173)\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t1.536795)\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t1.508990)\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t1.542599)\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t1.510567)\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t1.563294)\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t1.605053)\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t1.531285)\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t1.526013)\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t1.509971)\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t1.550616)\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t1.508398)\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t1.495102)\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t1.568547)\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t1.564990)\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t1.587455)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9671/10000 (97%\n",
      ")\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.529548)\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t1.530562)\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t1.526035)\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t1.551671)\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t1.534071)\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t1.547070)\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t1.525562)\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t1.524534)\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t1.546223)\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t1.503985)\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t1.529447)\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t1.513134)\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t1.508852)\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t1.537175)\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t1.519312)\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t1.517053)\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t1.521001)\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t1.528257)\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t1.554251)\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t1.531690)\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t1.507103)\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t1.514476)\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t1.511860)\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t1.622999)\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t1.562580)\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t1.558284)\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t1.542426)\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t1.540198)\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t1.530740)\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t1.536722)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9703/10000 (97%\n",
      ")\n",
      "Train Epoch: 7 [0/60000 (0%)]\t1.566501)\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t1.517818)\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t1.495222)\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t1.515283)\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t1.530390)\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t1.553410)\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t1.495705)\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t1.514582)\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t1.524582)\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t1.510834)\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t1.572460)\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t1.516521)\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t1.579919)\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t1.538691)\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t1.539930)\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t1.535200)\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t1.571393)\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t1.564479)\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t1.528715)\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t1.543450)\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t1.525278)\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t1.531376)\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t1.538060)\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t1.516950)\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t1.511088)\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t1.568401)\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t1.550079)\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t1.514385)\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t1.539740)\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t1.517836)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9719/10000 (97%\n",
      ")\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.528025)\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t1.560146)\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t1.526805)\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t1.527093)\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t1.502235)\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t1.532891)\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t1.516031)\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t1.547836)\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t1.532141)\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t1.535915)\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t1.507743)\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t1.564587)\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t1.542143)\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t1.573520)\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t1.513206)\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t1.523225)\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t1.503067)\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t1.570524)\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t1.564969)\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t1.525890)\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t1.552659)\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t1.502679)\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t1.550035)\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t1.527382)\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t1.516193)\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t1.542181)\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t1.545715)\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t1.509104)\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t1.539318)\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t1.524769)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9737/10000 (97%\n",
      ")\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.482845)\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t1.512583)\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t1.552154)\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t1.530006)\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t1.531839)\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t1.528049)\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t1.566864)\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t1.554894)\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t1.506363)\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t1.565651)\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t1.542316)\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t1.495022)\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t1.524110)\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t1.516498)\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t1.498812)\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t1.514892)\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t1.506765)\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t1.545738)\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t1.529451)\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t1.554787)\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t1.566307)\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t1.496379)\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t1.567525)\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t1.564238)\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t1.545098)\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t1.533121)\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t1.506928)\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t1.585499)\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t1.541333)\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t1.523525)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9753/10000 (98%\n",
      ")\n",
      "Train Epoch: 10 [0/60000 (0%)]\t1.509455)\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t1.540154)\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t1.545773)\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t1.552010)\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t1.495283)\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t1.518521)\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t1.528408)\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t1.526782)\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t1.534853)\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t1.520932)\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t1.511445)\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t1.520516)\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t1.519653)\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t1.530119)\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t1.550917)\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t1.544870)\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t1.546156)\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t1.516472)\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t1.520842)\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t1.504580)\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t1.560648)\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t1.537150)\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t1.510636)\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t1.529553)\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t1.501902)\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t1.518273)\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t1.575920)\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t1.524407)\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t1.492499)\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t1.546364)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9745/10000 (97%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbsElEQVR4nO3dfWyV9f3/8dfhpgfU9rBS29MjFAvesIjUDKVr0Iqjoe0MESUOb7bhYiRgMQO82bpN0W1ZHcsccWPozAaaCSLJgGiWelNpG2eLAyXEbDaUdGsRWpSl55RiC9LP7w9+nq9HCngdzun7tH0+kk/Sc13Xu9fbj1fOi+tcV6/jc845AQAwwEZYNwAAGJ4IIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgYZd3Al/X19engwYNKT0+Xz+ezbgcA4JFzTl1dXQqFQhox4sznOSkXQAcPHtTEiROt2wAAnKe2tjZNmDDhjOtT7iO49PR06xYAAAlwrvfzpAXQ2rVrdemll2rMmDEqLCzUu++++5Xq+NgNAIaGc72fJyWANm/erJUrV2rVqlV67733VFBQoNLSUh0+fDgZuwMADEYuCWbOnOkqKiqir0+ePOlCoZCrqqo6Z204HHaSGAwGgzHIRzgcPuv7fcLPgI4fP67du3erpKQkumzEiBEqKSlRQ0PDadv39vYqEonEDADA0JfwAPrkk0908uRJ5eTkxCzPyclRe3v7adtXVVUpEAhEB3fAAcDwYH4XXGVlpcLhcHS0tbVZtwQAGAAJ/zugrKwsjRw5Uh0dHTHLOzo6FAwGT9ve7/fL7/cnug0AQIpL+BlQWlqaZsyYoZqamuiyvr4+1dTUqKioKNG7AwAMUkl5EsLKlSu1aNEiXXvttZo5c6bWrFmj7u5u/eAHP0jG7gAAg1BSAmjhwoX6+OOP9dhjj6m9vV3XXHONqqurT7sxAQAwfPmcc866iS+KRCIKBALWbQAAzlM4HFZGRsYZ15vfBQcAGJ4IIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYSMrTsIHBatWqVZ5rvv/973uuWbhwoeeaXbt2ea4BUhlnQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEzwNG0PS7Nmz46pbvHix55pjx455rrn22ms91/A0bAw1nAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwcNIkfLS09M912zZsiWufT3//POea3784x97rnHOea4BhhrOgAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJjgYaRIeUuXLvVc09PTE9e+fvvb33qu+eyzz+LaFzDccQYEADBBAAEATCQ8gB5//HH5fL6YMXXq1ETvBgAwyCXlGtBVV12lN9988/92MopLTQCAWElJhlGjRikYDCbjVwMAhoikXAPat2+fQqGQJk+erLvvvlutra1n3La3t1eRSCRmAACGvoQHUGFhoTZs2KDq6mqtW7dOLS0tuuGGG9TV1dXv9lVVVQoEAtExceLERLcEAEhBCQ+g8vJy3X777Zo+fbpKS0v197//XZ2dnXr55Zf73b6yslLhcDg62traEt0SACAFJf3ugHHjxumKK65Qc3Nzv+v9fr/8fn+y2wAApJik/x3Q0aNHtX//fuXm5iZ7VwCAQSThAfTQQw+prq5O//nPf/TOO+/o1ltv1ciRI3XnnXcmelcAgEEs4R/BHThwQHfeeaeOHDmiiy++WNdff70aGxt18cUXJ3pXAIBBzOecc9ZNfFEkElEgELBuAynkk08+8Vzz7LPPxrWvn/70p3HVAThdOBxWRkbGGdfzLDgAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmkv6FdMAXpaene66J5wsLP/zwQ881AAYWZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABM8DRsDqqysbED2U11dPSD7ARA/zoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY4GGkGFBLlizxXNPb2+u55uOPP/ZcA2BgcQYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABA8jRdx8Pp/nmvHjx3uuqamp8VyD8zN79mzPNQsXLkx8I/3o7Oz0XFNfXx/Xvqqrqz3XOOfi2tdwxBkQAMAEAQQAMOE5gOrr6zVv3jyFQiH5fD5t27YtZr1zTo899phyc3M1duxYlZSUaN++fYnqFwAwRHgOoO7ubhUUFGjt2rX9rl+9erWefvppPfPMM9q5c6cuvPBClZaWqqen57ybBQAMHZ5vQigvL1d5eXm/65xzWrNmjX72s5/plltukSS98MILysnJ0bZt23THHXecX7cAgCEjodeAWlpa1N7erpKSkuiyQCCgwsJCNTQ09FvT29urSCQSMwAAQ19CA6i9vV2SlJOTE7M8Jycnuu7LqqqqFAgEomPixImJbAkAkKLM74KrrKxUOByOjra2NuuWAAADIKEBFAwGJUkdHR0xyzs6OqLrvszv9ysjIyNmAACGvoQGUH5+voLBYMxfrkciEe3cuVNFRUWJ3BUAYJDzfBfc0aNH1dzcHH3d0tKiPXv2KDMzU3l5eVq+fLl++ctf6vLLL1d+fr4effRRhUIhzZ8/P5F9AwAGOc8BtGvXLt10003R1ytXrpQkLVq0SBs2bNAjjzyi7u5uLV68WJ2dnbr++utVXV2tMWPGJK5rAMCg53Mp9uS8SCSiQCBg3Qa+glAo5LnmwIEDnmvuvvtuzzWbNm3yXJPq0tLSPNc8+eSTce1r+fLlnmtaW1s913R1dQ3Ifq6//nrPNZJ0++23e655/fXX49rXUBQOh896Xd/8LjgAwPBEAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDh+esYgIH28ccfW7eQcCNGeP+333PPPee55nvf+57nGkm6//77PdesX7/ec01vb6/nmnjE+31kzz77rOeaa665xnNNOBz2XDMUcAYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABA8jRdzy8vIGZD///Oc/B2Q/A+kPf/iD55q5c+cOSI0k1dTUeK5xzsW1r4Hw2muvxVU3ZswYzzUXXnih5xoeRgoAwAAigAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggoeRIm45OTnWLaSEYDDouWbevHmea+666y7PNTt27PBcMxR9+umncdU1Nzd7rrnhhhs812zevNlzzVDAGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATPIwUcTt+/PiA7GfChAmea8LhcBI66d93v/tdzzXxPMD0nXfe8VyDgZeenm7dwqDBGRAAwAQBBAAw4TmA6uvrNW/ePIVCIfl8Pm3bti1m/T333COfzxczysrKEtUvAGCI8BxA3d3dKigo0Nq1a8+4TVlZmQ4dOhQdmzZtOq8mAQBDj+ebEMrLy1VeXn7Wbfx+f1wXWQEAw0dSrgHV1tYqOztbV155pZYuXaojR46ccdve3l5FIpGYAQAY+hIeQGVlZXrhhRdUU1OjX//616qrq1N5eblOnjzZ7/ZVVVUKBALRMXHixES3BABIQQn/O6A77rgj+vPVV1+t6dOna8qUKaqtrdWcOXNO276yslIrV66Mvo5EIoQQAAwDSb8Ne/LkycrKylJzc3O/6/1+vzIyMmIGAGDoS3oAHThwQEeOHFFubm6ydwUAGEQ8fwR39OjRmLOZlpYW7dmzR5mZmcrMzNQTTzyhBQsWKBgMav/+/XrkkUd02WWXqbS0NKGNAwAGN88BtGvXLt10003R159fv1m0aJHWrVunvXv36vnnn1dnZ6dCoZDmzp2rX/ziF/L7/YnrGgAw6HkOoNmzZ8s5d8b1r7322nk1hMHj7bff9lzT3t7uuWbJkiWeax544AHPNfFqbGz0XDNqlPf7f2688UbPNa+//rrnmqEonvmWFNc16c7Ozrj2NRzxLDgAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgImEfyU3ho+uri7PNR999JHnmttvv91zzYoVKzzXSNJnn33mueZ///uf55q+vj7PNSNHjvRcg1PifTp6MBj0XFNTUxPXvoYjzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY8DnnnHUTXxSJRBQIBKzbQJIsXLjQc82LL77ouWbdunWea6T4H1rp1Z/+9CfPNTfffLPnmr/85S+eaySpp6cnrjqv3n77bc81eXl5nmuee+45zzWSVF5e7rlmx44dce1rKAqHw8rIyDjjes6AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOBhpEh5mzdv9lwzf/78uPa1Zs0azzVPPfWU55pwOOy5pqyszHNNVlaW5xpJ8vl8nmvS0tI811xxxRWeawoKCjzXPPjgg55rJGn37t1x1eEUHkYKAEhJBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATPAwUqS80aNHe6751a9+Fde+li9f7rnmo48+8lyzbds2zzVtbW2ea+IVz8NcZ82a5bmmpqbGc83DDz/suWbPnj2ea3D+eBgpACAlEUAAABOeAqiqqkrXXXed0tPTlZ2drfnz56upqSlmm56eHlVUVGj8+PG66KKLtGDBAnV0dCS0aQDA4OcpgOrq6lRRUaHGxka98cYbOnHihObOnavu7u7oNitWrNArr7yiLVu2qK6uTgcPHtRtt92W8MYBAIPbKC8bV1dXx7zesGGDsrOztXv3bhUXFyscDuvPf/6zNm7cqG9961uSpPXr1+vrX/+6Ghsb9c1vfjNxnQMABrXzugb0+dcKZ2ZmSjr19bUnTpxQSUlJdJupU6cqLy9PDQ0N/f6O3t5eRSKRmAEAGPriDqC+vj4tX75cs2bN0rRp0yRJ7e3tSktL07hx42K2zcnJUXt7e7+/p6qqSoFAIDomTpwYb0sAgEEk7gCqqKjQBx98oJdeeum8GqisrFQ4HI6OgfxbBwCAHU/XgD63bNkyvfrqq6qvr9eECROiy4PBoI4fP67Ozs6Ys6COjg4Fg8F+f5ff75ff74+nDQDAIObpDMg5p2XLlmnr1q166623lJ+fH7N+xowZGj16dMxfNzc1Nam1tVVFRUWJ6RgAMCR4OgOqqKjQxo0btX37dqWnp0ev6wQCAY0dO1aBQED33nuvVq5cqczMTGVkZOiBBx5QUVERd8ABAGJ4CqB169ZJkmbPnh2zfP369brnnnskSb/73e80YsQILViwQL29vSotLdUf//jHhDQLABg6eBgp8AWFhYWea77zne94rikuLvZcM3XqVM81tbW1nmsk6b333vNcU19f77lmx44dnmv6+vo818AGDyMFAKQkAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJnoYNAEgKnoYNAEhJBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE54CqKqqStddd53S09OVnZ2t+fPnq6mpKWab2bNny+fzxYwlS5YktGkAwODnKYDq6upUUVGhxsZGvfHGGzpx4oTmzp2r7u7umO3uu+8+HTp0KDpWr16d0KYBAIPfKC8bV1dXx7zesGGDsrOztXv3bhUXF0eXX3DBBQoGg4npEAAwJJ3XNaBwOCxJyszMjFn+4osvKisrS9OmTVNlZaWOHTt2xt/R29urSCQSMwAAw4CL08mTJ93NN9/sZs2aFbP82WefddXV1W7v3r3ur3/9q7vkkkvcrbfeesbfs2rVKieJwWAwGENshMPhs+ZI3AG0ZMkSN2nSJNfW1nbW7Wpqapwk19zc3O/6np4eFw6Ho6Otrc180hgMBoNx/uNcAeTpGtDnli1bpldffVX19fWaMGHCWbctLCyUJDU3N2vKlCmnrff7/fL7/fG0AQAYxDwFkHNODzzwgLZu3ara2lrl5+efs2bPnj2SpNzc3LgaBAAMTZ4CqKKiQhs3btT27duVnp6u9vZ2SVIgENDYsWO1f/9+bdy4Ud/+9rc1fvx47d27VytWrFBxcbGmT5+elP8AAMAg5eW6j87wOd/69eudc861tra64uJil5mZ6fx+v7vsssvcww8/fM7PAb8oHA6bf27JYDAYjPMf53rv9/3/YEkZkUhEgUDAug0AwHkKh8PKyMg443qeBQcAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMJFyAeScs24BAJAA53o/T7kA6urqsm4BAJAA53o/97kUO+Xo6+vTwYMHlZ6eLp/PF7MuEolo4sSJamtrU0ZGhlGH9piHU5iHU5iHU5iHU1JhHpxz6urqUigU0ogRZz7PGTWAPX0lI0aM0IQJE866TUZGxrA+wD7HPJzCPJzCPJzCPJxiPQ+BQOCc26TcR3AAgOGBAAIAmBhUAeT3+7Vq1Sr5/X7rVkwxD6cwD6cwD6cwD6cMpnlIuZsQAADDw6A6AwIADB0EEADABAEEADBBAAEATAyaAFq7dq0uvfRSjRkzRoWFhXr33XetWxpwjz/+uHw+X8yYOnWqdVtJV19fr3nz5ikUCsnn82nbtm0x651zeuyxx5Sbm6uxY8eqpKRE+/bts2k2ic41D/fcc89px0dZWZlNs0lSVVWl6667Tunp6crOztb8+fPV1NQUs01PT48qKio0fvx4XXTRRVqwYIE6OjqMOk6OrzIPs2fPPu14WLJkiVHH/RsUAbR582atXLlSq1at0nvvvaeCggKVlpbq8OHD1q0NuKuuukqHDh2Kjrffftu6paTr7u5WQUGB1q5d2+/61atX6+mnn9YzzzyjnTt36sILL1Rpaal6enoGuNPkOtc8SFJZWVnM8bFp06YB7DD56urqVFFRocbGRr3xxhs6ceKE5s6dq+7u7ug2K1as0CuvvKItW7aorq5OBw8e1G233WbYdeJ9lXmQpPvuuy/meFi9erVRx2fgBoGZM2e6ioqK6OuTJ0+6UCjkqqqqDLsaeKtWrXIFBQXWbZiS5LZu3Rp93dfX54LBoPvNb34TXdbZ2en8fr/btGmTQYcD48vz4JxzixYtcrfccotJP1YOHz7sJLm6ujrn3Kn/96NHj3ZbtmyJbvPvf//bSXINDQ1WbSbdl+fBOeduvPFG98Mf/tCuqa8g5c+Ajh8/rt27d6ukpCS6bMSIESopKVFDQ4NhZzb27dunUCikyZMn6+6771Zra6t1S6ZaWlrU3t4ec3wEAgEVFhYOy+OjtrZW2dnZuvLKK7V06VIdOXLEuqWkCofDkqTMzExJ0u7du3XixImY42Hq1KnKy8sb0sfDl+fhcy+++KKysrI0bdo0VVZW6tixYxbtnVHKPYz0yz755BOdPHlSOTk5MctzcnL04YcfGnVlo7CwUBs2bNCVV16pQ4cO6YknntANN9ygDz74QOnp6dbtmWhvb5ekfo+Pz9cNF2VlZbrtttuUn5+v/fv36yc/+YnKy8vV0NCgkSNHWreXcH19fVq+fLlmzZqladOmSTp1PKSlpWncuHEx2w7l46G/eZCku+66S5MmTVIoFNLevXv1ox/9SE1NTfrb3/5m2G2slA8g/J/y8vLoz9OnT1dhYaEmTZqkl19+Wffee69hZ0gFd9xxR/Tnq6++WtOnT9eUKVNUW1urOXPmGHaWHBUVFfrggw+GxXXQsznTPCxevDj689VXX63c3FzNmTNH+/fv15QpUwa6zX6l/EdwWVlZGjly5Gl3sXR0dCgYDBp1lRrGjRunK664Qs3NzdatmPn8GOD4ON3kyZOVlZU1JI+PZcuW6dVXX9WOHTtivr4lGAzq+PHj6uzsjNl+qB4PZ5qH/hQWFkpSSh0PKR9AaWlpmjFjhmpqaqLL+vr6VFNTo6KiIsPO7B09elT79+9Xbm6udStm8vPzFQwGY46PSCSinTt3Dvvj48CBAzpy5MiQOj6cc1q2bJm2bt2qt956S/n5+THrZ8yYodGjR8ccD01NTWptbR1Sx8O55qE/e/bskaTUOh6s74L4Kl566SXn9/vdhg0b3L/+9S+3ePFiN27cONfe3m7d2oB68MEHXW1trWtpaXH/+Mc/XElJicvKynKHDx+2bi2purq63Pvvv+/ef/99J8k99dRT7v3333f//e9/nXPOPfnkk27cuHFu+/btbu/eve6WW25x+fn57tNPPzXuPLHONg9dXV3uoYcecg0NDa6lpcW9+eab7hvf+Ia7/PLLXU9Pj3XrCbN06VIXCARcbW2tO3ToUHQcO3Ysus2SJUtcXl6ee+utt9yuXbtcUVGRKyoqMuw68c41D83Nze7nP/+527Vrl2tpaXHbt293kydPdsXFxcadxxoUAeScc7///e9dXl6eS0tLczNnznSNjY3WLQ24hQsXutzcXJeWluYuueQSt3DhQtfc3GzdVtLt2LHDSTptLFq0yDl36lbsRx991OXk5Di/3+/mzJnjmpqabJtOgrPNw7Fjx9zcuXPdxRdf7EaPHu0mTZrk7rvvviH3j7T+/vslufXr10e3+fTTT93999/vvva1r7kLLrjA3Xrrre7QoUN2TSfBueahtbXVFRcXu8zMTOf3+91ll13mHn74YRcOh20b/xK+jgEAYCLlrwEBAIYmAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJv4fuCDeN1j1DvEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[100]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "pred = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f\"Prediction: {pred}\")\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
